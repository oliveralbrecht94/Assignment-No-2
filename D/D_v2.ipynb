{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D SF Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describe challenges you faced during A, B and C and how you solved it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probleme bei A:\n",
    "\n",
    "1) Anfangs war es sehr schwer einen Überblick über den Datensatz zu  bekommen, daher haben wir auch lange gebraucht, um den Datensatz zu verstehen. Es waren einfach zu viele Spalten und zu viele unterschiedliche  Zuständigkeiten. Vor allem wussten wir zu Beginn nicht, was die einzelen Spalten aussagen\n",
    "\n",
    "**Lösung:** Wir haben uns die CSV Datei in Excel anzeigen lassen und über die Filterfunktion den Datensatz verstehen können\n",
    "\n",
    "2) Es war ebenfalls nicht einfach zu entscheiden, welche Daten wir ignorieren und welche wir imputieren bzw. ob wir die Spalte überhaupt benötigen oder nicht. Wir haben uns hier anfangs immer die Frage gestellt: Ist das wichtig? Später haben wir uns dann auf die fehlenden Werte konzentriert und ob es eine Möglichkeit gibt es zu imputieren oder es nicht sinnvoll ist, da zu viele Daten fehlen. Wir konnten uns hier auf kein Richtig oder Falsch einigen.\n",
    "\n",
    "**Lösung:** Hier hat uns nur Try and error geholfen. Wir haben uns einfach am Datensatz versucht und nach und nach verschiedene Möglichkeiten entdeckt. Als Gruppe haben wir uns letzendlich geeinigt, dass wir rationale Entscheidungen treffen und alle Spalten bei denen mehr als 50% der Daten fehlen, ignoriert werden. Durch das Sichten über Excel, konnten wir auch \"relativ\" schnell Zusammenhänge (Existing/Proposed) finden. Das hat uns später beim Ignorieren und imputieren der Spalten geholfen.So konnten wir nach und nach die fehlenden Werte minimieren\n",
    "\n",
    "3) Manchmal gab es bei bestimmten Tasks zwei Lösungen. Beispielweise bei der Imputation konnten wir ebenfalls auch die Zeilen löschen. Für uns war hier nicht auf den ersten Blick ersichtlich, ob wir imputieren oder löschen sollten. \n",
    "\n",
    "**Lösung:** Wir hatten uns hier die gesamte Prozentzahl der fehlenden Daten anzeigen lassen (3,6%) und haben uns hier anfangs dazu leiten lassen, einfach die Zeilen zu löschen. Danach ist uns aufgefallen, dass wir durch das Löschen der Zeilen fast 26% der Daten verloren haben. Logischerweise haben wir uns dann dazu entschieden die Daten zu imputieren. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probleme bei B:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Zu Beginn fiel es uns schwer den richtigen Einstiegspunkt zu finden. Wie finden wir raus, welche Spalten am besten mit dem Current Status korrelieren? Zu erst wollten wir jede Spalte über einen Plot mit dem Current Status testen. Dann haben wir gemerkt, dass wir die Spalte erst verändern müssen.\n",
    "\n",
    "**Lösung:** wir haben zuerst die zweite Frage vorgezogen und die Current Status Spalte in eine binäre Spalte 0/1 transformiert\n",
    "\n",
    "2) Bei Frage eins testeten wir uns erstmal durch. Wir haben begonnen, uns die Korrelation von einzelne Spalten mit dem Current Status anzeigen zu lassen und gemerkt, dass das für alle Spalten extrem mühsam ist.\n",
    "\n",
    "**Lösung:** Nach einigen Ausgaben haben wir uns überlegt, mit Hilfe eine Korrelationstabelle/Heatmap einfach auf den ersten Blick die Korrelation der Spalten mit dem Current Status zu sehen. Über Google konnten wir auch schnell die richtigen Befehle ausfindig machen und diese erfolgreich anwenden.\n",
    "\n",
    "3) Nachdem wir die Heatmap implementiert hatte, konnten wir zwar durch die Einfärbungen sehen, dass es eine positive/negative Korrelation gibt, aber nicht wie stark/schwach diese ist.\n",
    "\n",
    "**Lösung:** Um unsere Aussagekraft zu stärken, haben wir für die auffälligen Tabellen einfach die Korrelation berechnet und ausgegeben. So konnten wir auf einen Blick sehen, wie stark/schwach die Korrelation ist. Im Nachhinein hat die Einfärbung des Rechtecks auch oft getäuscht und die Korrelation war gar nicht so stark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probleme bei C:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Als wir die \"one-hot encoded dummies\" erstellt haben, mussten wir alle Spalten berücksichtigen die noch Kategorien enthalten haben. Hier war unter anderem auch Street Name dabei. Das hat beim initalen Versuch dazu geführt, dass wir nach der Ausführung über 1800 Spalten hatten, da er für jeden Street Name eine Spalte erstellt hatte.\n",
    "\n",
    "**Lösung:** Wir haben uns hier logischerweise entschieden, den Street Name aufgrund der hohen Anzahl an Kategorien zu ignorieren.\n",
    "\n",
    "2) Bei der Wahl des Predictor wussten wir nicht welchen wir wählen sollten, da unser Ziel war, eine möglichst hohe Accuracy zu erhalten. \n",
    "\n",
    "**Lösung:** Wir haben uns im Interent über ein paar Predictor informiert und verschiedene Lösungen betrachtet. Danach wurde insgesamt 4 Modelle implementiert und der mit der höchsten Accuracy implementiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
